---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---

```{r}
# Load the libraries

library("Amelia")
library("MatchIt")
library("Zelig")
library("sandwich")
library("twang") # library for ps() function
library("cluster")
library("rlist")
#library("wiggleplotr")
library("dplyr")
#library("GenomicRanges")
#library("GenomicFeatures")
#library("biomaRt")
```



```{r}
# Clear any existing variables
rm(list = ls())

# Set seed for reproducibility
set.seed(1)

dir_HTE = "~/Documents/Projects/HTE/"
dir_data = "data/data_preprocessed_tbi_individuals.csv"

# Load pretreated_dataset
pretreated_dataset <- read.csv(paste(dir_HTE, dir_data, sep = ""), header = TRUE)
summary(pretreated_dataset)
pretreated_dataset <- pretreated_dataset %>% filter(GCS.init >= 9)


# These are the covariates we'll use

cts_variables_names <- c("SBP.ph", "DBP.ph", "HR.ph", "Shock.index.ph", "Delta.shock.index", "Cristalloid.volume", "Colloid.volume", "HemoCue.init", "Delta.hemoCue", "SpO2.ph.min")

binary_variables_names <- c("Vasopressor.therapy", "AIS.external", "Cardiac.arrest.ph")

levels(pretreated_dataset$Cardiac.arrest.ph) <- c(0,1)

categorical_variables_names <- c("Trauma.center")

covariates <- c(cts_variables_names, binary_variables_names, categorical_variables_names)

all_variables_names <- c(covariates, "Death", "Tranexamic.acid")

```


<!-- Missing Values -->
<!-- ```{r} -->
<!-- pMiss <- function(x){ -->
<!--   sum(is.na(x)/length(x) * 100) -->
<!-- } -->
<!-- pretreated_dataset %>% filter(W == 0) %>% apply(2, pMiss) -->
<!-- ``` -->


```{r}
# Now let's complet the dataframe using Amelia
m = 1
noms = c(binary_variables_names)
idvars = c("Death", "Tranexamic.acid", categorical_variables_names)
a.out <- amelia(pretreated_dataset[, all_variables_names], m = m, noms = noms, idvars = idvars)
pretreated_completed_dataset <- a.out$imputations$imp1

# write.csv(dfcomp, file = paste(dir_HTE, "data/amelia_comp_dataset.csv", sep = ""))
# 
# # Let's define the variables
# Xcomp = dfcomp[, !names(dfcomp) %in% c("Y", "W", "X")]
# Ycomp = dfcomp$Y
# Wcomp = dfcomp$W

```


```{r}
# Extracting and scaling continuous variables
scaled_cts_covariates <- pretreated_completed_dataset %>%
  dplyr::select(cts_variables_names) %>%  
  scale()

# Extracting  indicator variables
binary_covariates <- pretreated_completed_dataset %>%
  dplyr::select(binary_variables_names)
categorical_covariates <- pretreated_completed_dataset %>%
  dplyr::select(categorical_variables_names)

# Extracting outcome and treatment

outcome <- pretreated_completed_dataset %>% dplyr::select(Death)
treatment <- pretreated_completed_dataset %>% dplyr::select(Tranexamic.acid) 

# Setting up the data with only the variables of interest, and renaming columns
dfcomp <- data.frame(categorical_covariates, scaled_cts_covariates, binary_covariates, outcome, treatment) %>% plyr::rename(c(Tranexamic.acid = "W", Death = "Y"))
dfcomp$X <- rownames(dfcomp)

# Reorder column X
dfcomp <- dfcomp[, c("X", colnames(dfcomp)[colnames(dfcomp) != "X"])]

# Change type of binary variables
dfcomp[, c(binary_variables_names, categorical_variables_names)] <- sapply(dfcomp[, c(binary_variables_names, categorical_variables_names)], as.numeric)

# Write data complete data to CSV
write.csv(dfcomp, file = paste(dir_HTE, "data/amelia_comp_dataset.csv", sep = ""))

# Let's define the variables
Xcomp = dfcomp[, !names(dfcomp) %in% c("Y", "W", "X")]
Ycomp = dfcomp$Y
Wcomp = dfcomp$W

# Define the Formula used on the treatment
psFormula = as.formula(paste("W ~", paste(covariates, collapse = " + ")))
```



Propensity Score Calculation

```{r}
# Computing the propensity socre by logistic regression of W on X
p_logistic <- function(dataset){
  p_logistic.fit <- glm(Wcomp ~ as.matrix(sapply(Xcomp, as.numeric)), family = "binomial")
  p_logistic <- predict(p_logistic.fit, type = "response")
  hist(p_logistic)
  return (p_logistic)
}
dfcomp$p.logistic <- p_logistic(dfcomp)

# Let's check if the regression is well calibrated
{plot(smooth.spline(dfcomp$p.logistic, Wcomp, df = 4))
  abline(0,1)}

#Estimate propensity scores with generalized boosted modeling (GBM)
gbm_ps <- function(dataset, psFormula){
  # es: refers to standardized ef-fect size.
  myGBM <- ps(psFormula, data = dataset, n.trees=10000, interaction.depth=4,
              shrinkage=0.01, stop.method=c("es.max"), estimand = "ATT",
              verbose=TRUE)

  #extract estimated propensity scores from object
  gbm_estimations <- myGBM$ps[, 1]
  # notice here we do not need to
  return(gbm_estimations)
}
p_gbm <- gbm_ps(dfcomp, psFormula = psFormula)
dfcomp$propensity.score.gbm <- p_gbm
hist(dfcomp$propensity.score.gbm)
```



```{r ols_regression}
# Direct conditional mean estimation
# Let's define the conditional average treatment effect (CATE)
ate_condmean_ols <- function(dataset) {
  df_centered = data.frame(scale(dataset[, !names(dataset) %in% c("X", "p.logistic", "p.gbm")], center = TRUE, scale = FALSE))
  # Running OLS with full interactions is like running OLS separately on
  # the treated and controls. If the design matrix has been pre-centered,
  # then the W-coefficient corresponds to the ATE.
  lm.interact = lm(Y ~ . * W, data = df_centered)
  tau.hat = as.numeric(coef(lm.interact)["W"])
  se.hat = as.numeric(sqrt(vcovHC(lm.interact, type = "HC")["W", "W"]))
  return ( c(ATE=tau.hat, lower_ci = tau.hat - 1.96 * se.hat, upper_ci = tau.hat + 1.96 * se.hat) )
}

# Now let's estimate the ATE using Inverse-propensity score weighting
ipw <- function(dataset, p) {
  W <- dataset$W
  Y <- dataset$Y
  G <- ((W - p) * Y) / (p * (1-p))
  tau.hat <- mean(G)
  se.hat <- sqrt(var(G) / (length(G) - 1))
  return ( c(ATE = tau.hat, lower_ci = tau.hat - 1.96 * se.hat, upper_ci = tau.hat + 1.68 * se.hat) )
}

# Now Weighted OLS on W
prop_score_ols <- function(dataset, p) {
  # Pulling relevant columns
  W <- dataset$W
  Y <- dataset$Y
  # Computing weights
  weights <- (W / p) + ((1 - W) / (1 - p))
  # OLS
  lm.fit <- lm(Y ~ W, data = dataset[, !names(dataset) %in% c("X")], weights = weights)
  tau.hat = as.numeric(coef(lm.fit)["W"])
  se.hat = as.numeric(sqrt(vcovHC(lm.fit, type = "HC")["W", "W"]))
  return ( c(ATE=tau.hat, lower_ci = tau.hat - 1.96 * se.hat, upper_ci = tau.hat + 1.96 * se.hat) )
}

# Now the double robust
aipw_ols <- function(dataset, p) {
  
  ols.fit = lm(Y ~ W * ., data = dataset[, !names(dataset) %in% c("X", "p.logistic", "p.gbm", "Trauma.center")])
  
  dataset.treatall = dataset
  dataset.treatall$W = 1
  treated_pred = predict(ols.fit, dataset.treatall)
  
  dataset.treatnone = dataset
  dataset.treatnone$W = 0
  control_pred = predict(ols.fit, dataset.treatnone)
  
  actual_pred = predict(ols.fit, dataset)
  
  G <- treated_pred - control_pred +
    ((dataset$W - p) * (dataset$Y - actual_pred)) / (p * (1 - p))
  tau.hat <- mean(G)
  se.hat <- sqrt(var(G) / (length(G) - 1))
  return ( c(ATE=tau.hat, lower_ci = tau.hat - 1.96 * se.hat, upper_ci = tau.hat + 1.96 * se.hat) )
}

dfcomp
# results

tauhat_ols <- ate_condmean_ols(dfcomp)
tauhat_logistic_ipw <- ipw(dfcomp, dfcomp$p.logistic)
tauhat_pscore_ols <- prop_score_ols(dfcomp, dfcomp$p.logistic)
tauhat_lin_logistic_aipw <- aipw_ols(dfcomp, dfcomp$p.logistic)

#print of the results
results_prop = rbind(tauhat_ols, 
                     tauhat_logistic_ipw, 
                     tauhat_pscore_ols, 
                     tauhat_lin_logistic_aipw)
print(results_prop)

```

Now since we have an estimation of the ATE, let's cluster the dataset using the propensity score as a distance using different clustering methods


Estimating TE (Treatment Effect on Treated) using a matched 1:1 dataset #TO FAZENDO - LUIZ

```{r}

# estimate_treatment_effect <- function(dataset, match.matrix){
#   treated <- dataset %>% filter(W == 1) %>% select(X, Y)
#   control <- dataset %>% filter(W == 0) %>% select(X, Y)
#   for (i in treated)
#     i$Y_matched <- control %>% filter(X == match.matrix[i$X]) %>% select(Y)
# }
# 
# treated <- dfcomp %>% filter(W == 1) %>% select(X, Y)
# control <- dfcomp %>% filter(W == 0) %>% select(X, Y)
# 
# for (i in treated)
#     i$Y_matched <- control %>% filter(X == greedymatching$match.matrix[i$X]) %>% select(Y)

```


I) Clustering using Matching - Using the library MatchIt # MUDAR NOME TA ERRADO SSAPORRA
i) Nearest-Neighbor Propensity Score Matching, with Propensity Score estimated with Logistic Regression # Ã‰ 1:1
```{r greedymatching}

# # Matching on Nearest Neighbor
# neighbor_matching <- function(psFormula, distance, data, method = "nearest", ...) {
#   return(matchit(psFormula, distance = distance, data = data, method = method, ...))
# }
# 
# greedymatching <- neighbor_matching(psFormula, distance = p_logistic, data = dfcomp, method = "nearest")
# #greedy_s.out <- get_estimated_treatment(greedymatching, zeFormula)
# #summary(greedy_s.out)

```


ii) Nearest-Neighbor Propensity Score Matching, with Propensity Score estimated with XGBoost
```{r}

```
  

Genetic Matching (1:1)
```{r}
# # perform genetic matching based on all the covariates and the propensity score estimated from GMB
# calc_geneticMatchin_with_gmb = function(data, psFormula, zeFormula, Ps_scores){
#   geneticMatching <- matchit(psFormula, distance = Ps_scores,
#                            data = data, method = "genetic",pop.size=1000,
#                            fit.func = "pvals",
#                            estimand = "ATT", replace = T, ties = T, discard = "both")
# }
# 
# calc_geneticMatchin_with_gmb(dfcomp, psFormula, zeFormula, Ps_scores = dfcomp$propensity.score.gbm)
```


Estimating ATT #CAGA DPS ARRUMA
```{r}
# get_estimated_treatment <- function(matching_output, zeFormula){
#   z.out <- zelig(zeFormula, data = match.data(matching_output, "control"), model = "ls")
#   x.out <- setx(z.out, data = match.data(matching_output, "treat"), cond = TRUE)
#   s.out <- sim(z.out, x = x.out)
#   return (s.out)
# }
# zeFormula = Ycomp ~ as.matrix(sapply(Xcomp, as.numeric))
```

Clustering with  PAM clustering algorithm
https://towardsdatascience.com/clustering-on-mixed-type-data-8bbd0a2569c3
Distance -> Gower distance (explain better)

```{r}
n_clusters <- 4
set.seed(1)
pam_clustering <- function(dataset, n_clusters){
  # Receives the full dataset from which we only use the covariates and the algorithm infers the distance using Gower Distance
  # Change the type of the variables to categorical
  dataset[, binary_variables_names] <- as.data.frame(sapply(dataset[, binary_variables_names], as.factor))

  gower_dist <- daisy(dataset[, c(cts_variables_names, binary_variables_names)], metric = "gower") # We only use the covariates
  gower_mat <- as.matrix(gower_dist)
  
  # Do the clustering
  pam_fit <- pam(gower_dist, diss = TRUE, k = n_clusters) 
  temp_df <- dataset %>% mutate(cluster = pam_fit$clustering)
  temp_df [, binary_variables_names] <- temp_df[, binary_variables_names] %>% sapply(as.numeric) %>% as.data.frame(.)
  #res <- list()
  # for (i in 1:n_clusters){
  #   cluster_i <- temp_df %>% filter(cluster == i)
  #   cluster_i$cluster <- NULL # Remove useless column
  # 
  #   # Change the type of the variables to numerical
  #   cluster_i[, binary_variables_names] <- as.data.frame(sapply(cluster_i[, binary_variables_names], as.numeric))
  #   res <- res %>% list.append(cluster_i)
  # }
  
  # Undo changes
 

  return (temp_df)
}

  # Let's take a look in the sillhouette
# sil_width <- c(NA)
# for(i in 2:8){  
#   pam_fit <- pam(gower_dist, diss = TRUE, k = i)  
#   sil_width[i] <- pam_fit$silinfo$avg.width  
# }
# plot(1:8, sil_width,
#      xlab = "Number of clusters",
#      ylab = "Silhouette Width")
# lines(1:8, sil_width)

# Let's use then 4 clusters

pam_clusters <- pam_clustering(dfcomp, n_clusters)

# Now, for each cluster, we will calculate the ATE using all the methods explicited above

cluster_info <- function(dataset, cluster_number){
  cluster_i <- dataset %>% filter(cluster == i)
  
  # The means
  mean_p.logistic_before <- c( mean_p.logistic = mean(cluster_i$p.logistic))
  mean_p.gbm_before <- c(mean_p.gbm = mean(cluster_i$propensity.score.gbm))
  n_treated <- nrow(cluster_i %>% filter(W == 1)) %>% as.integer() %>% c(n_treated = .)
  n_control_before <- nrow(cluster_i %>% filter(W == 0)) %>% as.integer() %>% c(n_control = .)
  
  # The ATE estimations before matching
  
  all_ATE_estimations_before <- c(
    linear_regression = ate_condmean_ols(cluster_i) ["ATE"],  # Linear regrssion
    IPW_logistic = ipw(cluster_i, cluster_i$p.logistic)["ATE"],  # IPW with logistic propensity score
    propensity_weighted_regression = prop_score_ols(cluster_i, cluster_i$p.logistic)["ATE"],  # Propensity weighted regression
    AIPW_linear_plus_logistic = aipw_ols(cluster_i, cluster_i$p.logistic)["ATE"]  # Double robust
  )
  
 cluster_estimations_before_matching <- c(n_treated, n_control_before, mean_p.logistic_before, mean_p.gbm_before, all_ATE_estimations_before)

 # Now we do a matching to balance the number of control and treated on the dataset (discarding the excess of control patients) to see how it changes the results
 # We will keep track only the AIPW before matching and after matching to compare
 
 matched_cluster <- matchit(psFormula, data = cluster_i, method = "genetic", discard = "control") %>% match.data() %>% as.data.frame()
 
 # The means After matching
 mean_p.logistic_after <- c( mean_p.logistic = mean(matched_cluster$p.logistic))
 mean_p.gbm_after <- c(mean_p.gbm = mean(matched_cluster$propensity.score.gbm))
 n_treated <- nrow(matched_cluster %>% filter(W == 1)) %>% as.integer() %>% c(n_treated = .)
 n_control_after <- nrow(matched_cluster %>% filter(W == 0)) %>% as.integer() %>% c(n_control = .)

 # Do the same calculations
 ATE_estimations <- c(
   AIPW_linear_plus_logistic_before =  aipw_ols(cluster_i, cluster_i$p.logistic)["ATE"], # Before matching
   AIPW_linear_plus_logistic_after = aipw_ols(matched_cluster, matched_cluster$p.logistic)["ATE"]  # Double robust after matching
  )
  
 cluster_estimations_after_matching <- c(n_treated, n_control_before = n_control_before, n_control_after = n_control_after, mean_p.logistic_after = mean_p.logistic_after, ATE_estimations)

 return(list(cluster_estimations_before_matching, cluster_estimations_after_matching))
}
dataset

(matched_cluster %>% filter(Y == 1, W == 1) %>% nrow(.)) - (matched_cluster %>% filter(Y == 1, W == 0) %>% nrow(.))
matched_cluster %>% filter(Y == 1, W == 0) %>% nrow(.)

cf <- (list(cluster_estimations_before_matching, cluster_estimations_after_matching))
cf <- cluster_info(pam_clusters, 1)

# all_cluster_estimations_before_matching <- c()
# all_cluster_estimations_after_matching <- c()
# for (i in 1:n_clusters){
#   # The means
#   mean_p.logistic_before <- c( mean_p.logistic = mean(pam_clusters[[i]]$p.logistic))
#   mean_p.gbm_before <- c(mean_p.gbm = mean(pam_clusters[[i]]$propensity.score.gbm))
#   n_treated <- nrow(pam_clusters[[i]] %>% filter(W == 1)) %>% as.integer() %>% c(n_treated = .)
#   n_control_before <- nrow(pam_clusters[[i]] %>% filter(W == 0)) %>% as.integer() %>% c(n_control = .)
#   
#   # The ATE estimations
#   
#   all_ATE_estimations <- c(
#     linear_regression = ate_condmean_ols(pam_clusters[[i]]) ["ATE"],  # Linear regrssion
#     IPW_logistic = ipw(pam_clusters[[i]], pam_clusters[[i]]$p.logistic)["ATE"],  # IPW with logistic propensity score
#     propensity_weighted_regression = prop_score_ols(pam_clusters[[i]], pam_clusters[[i]]$p.logistic)["ATE"],  # Propensity weighted regression
#     AIPW_linear_plus_logistic = aipw_ols(pam_clusters[[i]], pam_clusters[[i]]$p.logistic)["ATE"]  # Double robust
#   )
#   
#  all_cluster_estimations_before_matching <- rbind(all_cluster_estimations_before_matching, c(n_treated, n_control_before, mean_p.logistic_before, mean_p.gbm_before, all_ATE_estimations))
#  rownames(all_cluster_estimations_before_matching) <- c()
#  
#  
#  # Now we do a matching to balance the number of control and treated on the dataset (discarding the excess of control patients) to see how it changes the results
#  # We will keep track only the AIPW before matching and after matching to compare
#  
#  matched_cluster <- matchit(psFormula, data = pam_clusters[[i]], method = "genetic", discard = "control") %>% match.data() %>% as.data.frame()
#  
#  # The means After matching
#  mean_p.logistic_after <- c( mean_p.logistic = mean(matched_cluster$p.logistic))
#  mean_p.gbm_after <- c(mean_p.gbm = mean(matched_cluster$propensity.score.gbm))
#  n_treated <- nrow(matched_cluster %>% filter(W == 1)) %>% as.integer() %>% c(n_treated = .)
#  n_control_after <- nrow(matched_cluster %>% filter(W == 0)) %>% as.integer() %>% c(n_control = .)
# 
#  # Do the same calculations
#  ATE_estimations <- c(
#    AIPW_linear_plus_logistic_before =  aipw_ols(pam_clusters[[i]], pam_clusters[[i]]$p.logistic)["ATE"], # Before matching
#    AIPW_linear_plus_logistic_after = aipw_ols(matched_cluster, matched_cluster$p.logistic)["ATE"]  # Double robust after matching
#   )
#   
#  all_cluster_estimations_after_matching <- rbind(all_cluster_estimations_after_matching, c(n_treated, n_control_before = n_control_before, n_control_after = n_control_after, mean_p.logistic_after = mean_p.logistic_after, ATE_estimations))
#  rownames(all_cluster_estimations_after_matching) <- c()
# }
# all_cluster_estimations_before_matching
# 
# all_cluster_estimations_after_matching
# matchit(psFormula, data = pam_clusters[[i]], method = "nearest", discard = "control") %>% match.data() %>% as.data.frame()
# temp_kmeans <- dfcomp
# km <- kmeans(temp_kmeans[, 3:15], n_clusters)
# temp_kmeans <- cbind(temp_kmeans, cluster = km$cluster)
# result <- c()
# Cluster <- c()
# for (i in 1:n_clusters){
#   Cluster <- c(i, treated = nrow(temp_kmeans %>% filter(cluster == i, W == 1)), control = nrow(temp_kmeans %>% filter(cluster == i, W == 0)) )
#   result <- rbind(result, Cluster)
# }
# print(result)
```
```{r}

```

